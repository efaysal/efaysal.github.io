

<!-- 
git add --all
git commit -m "Initial commit"
 git push -u origin master

 -->

<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Analytics & Metrics </title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
    <script>
        $('body').ready(function() {
            // preload iframe with message
            var iframe = document.getElementById('show');
            var iframedoc = iframe.contentDocument || iframe.contentWindow.document;
            iframedoc.body.innerHTML = ''
                + '<br><br>'
                + '<div style="text-align: center; color: #000000; font-family: arial; font-size: 20px; font-weight:bold;">'
                + 'To load the Bursting Velocity'
+ '<br><br>'
                + ' Click above: Category or Video'
+ '<br><br>'
                + '</div>';

            $('.showbases').click(function(evt){
                evt.preventDefault();
                evt.stopPropagation();
                $(evt.target).fadeOut();
                $('.chartlinks').stop().slideUp({complete: function() {
                    $('.showcharts').fadeIn();
                    $('.baselinks').slideDown();
                }});
            });
            $('.showcharts').click(function(evt){
                evt.preventDefault();
                evt.stopPropagation();
                $(evt.target).fadeOut();
                $('.baselinks').stop().slideUp({complete: function() {
                    $('.showbases').fadeIn();
                    $('.chartlinks').slideDown();
                }});
            });
            $('.examplelinks a').each(function(i, elem) {
                $(elem).click(function(evt) {
                    $('#show').prop('src', $(evt.target).prop('href'));
                    evt.stopPropagation();
                    evt.preventDefault();
                    $('.examplelinks a').removeClass('selected');
                    $(evt.target).addClass('selected');
                    // add link to source
                    var urlparts = $(evt.target).prop('href').split('/');
                    var file = urlparts[urlparts.length - 1];
                    var sourceurl = 'https://github.com/nvd3-community/nvd3/blob/gh-pages/examples/' + file;
                    $('#tosource').prop('href', sourceurl).fadeIn();
                    // also set link to view only the example
                    $('#showonlythis').prop('href', $(evt.target).prop('href'));
                    // done
                    $('#example_options').attr('style', '');
                    return false;
                });
            });
        });
    </script>
    <meta name="viewport" content="width=device-width, initial-scale=55, user-scalable=no">

</head>
<body>

<header>
    <body style="background-color:lightgrey;">
      <h2 style="color:black">  Combining Nanoscopy Epi-Mark Imaging &amp Deep Discrepancy Learning Process </h2>
    <h2 style="color:black">  Predicting Lineage Progression of Stem Cells </h2>
    <div>
    <a target="alone"  href="https://github.com/efaysal" style="color:black"> Faysal.El.Khettabi@gmail.com </a>
     </div> 
</header>


<div class="wrapper">
    <nav>
        <ul></ul>
    </nav>
    <section>
    <!--   Under Construction and Review! -->
    <h1>  Aim and Motivation </h1>  

     Our aim is to illustrate how to use our <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/FLOURESCENCEIMAGECONTENTANALYTICS.html">Discrepancy Imaging Analytics</a> to analyze 
     <a target="alone"  href="https://www.youtube.com/watch?v=YyBGiZZSslY">
      Stimulated emission depletion (STED) microscopy images</a>.
  <br>  
  As illustration, we use this interesting recently published work <a target="alone"  href="http://www.nature.com/articles/srep39406">"Optical High Content Nanoscopy of Epigenetic Marks Decodes Phenotypic Divergence in Stem Cells"</a> that demonstrated a new way to identify the state and fate of individual stem cells earlier than previously possible.  <a target="alone"  href="https://stemcells.nih.gov/"> Stem cells </a>  
  can develop into different cell types. They may offer a renewable source of replacement cells to treat diseases, conditions, and disabilities, i.e. serving as building blocks for the various tissues and organs of the body to cure or reduce the severity in case of a disease or disorder. Stem cell and regenerative medicine research hold a great deal of promise. Understanding and accurately defining a stem cell phenotypic divergence are essential for using them in life saving therapies, improve  overall health and quality of life.
 <br>   <br> 
 The approach in the cited work is called EDICTS (Epi-mark Descriptor Imaging of Cell Transitional States), the work used the optical
high content nanoscopy of histone epigenetic marks (epi-marks) in stem cells to classify emergent cell states, i.e. involves imaging the labeled epigenetic modifications using microscopes capable of super resolution imaging as <a target="alone"  href="https://www.youtube.com/watch?v=YyBGiZZSslY"> Stimulated emission depletion (STED) microscopy images</a>.
<br>   <br> 
The main hypothesis in this EDICTS, " the phenotypic divergence in stem cells can be linked to the perturbation
of gene organizational domains within the nucleus, which can be detected and parametrized to the extent that the
derived parameters can forecast a specific lineage choice."
<br>   <br> 
The work also considered that the observed changes in the collected lights during a number of time-periods are faithful representation of histone epigenetic marks modifications (chromatin reorganizations) and not "dramatically" biased by the cell-living/nucleus dynamics, imaged side changes due to random elongation &amp 3D-rotation &amp shifts, during the process of recording/sampling spots(small groups of individual nucleosomes) to construct the images. 
 <br>   <br> 
The constructed images have the following characteristics:
 <ul>
   <li type="square"> The red color represents H3K27me3, the green color represents H3K4me3 and the blue color is redundant in the color-spaces of the image.  </li> 
     <li type="square"> The resolution of single pixel units correspond to the occupation of 1â€“4 nucleosomes.
   </li>
</ul>
 The authors combined their super-resolution imaging of single cell organizational features of epi-marks with "second order" texture calculations based on the Grey Level Co-occurrence Matrices (GLCMs) to derive insights about the stem cell's fate evolution. 
 The "second order" texture calculations consider mainly the relationship between two close pixels in the primary image to derive a number of descriptors derived from  GLCMs sensitive to the organizational distribution of neighboring pixel values. These large number of descriptors are reduced using principal component analysis (PCA) to compute three principal components for predicting the phenotypic divergence in stem cells. 

 <br>   <br> 

 In this essay, we are mainly motivated to test and assess the utility of our recent developed software <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/FLOURESCENCEIMAGECONTENTANALYTICS.html">Fluorescence Imaging Analysis Using Deep Discrepancy Learning Process </a> to automatically quantify the most informative and relevant features contained in the primary image generated by EDICTS. 
<br>   <br> 
We consider our recent developed software as a practical way of looking at third order texture. The framework is based on the
mathematical formulation of L2 discrepancy that measures the pixel-colors presence in all multiresolution-subrectangles defining the color-spaces, i.e. captured lights in the image and is providing an indication, without loss of spatial information,  related to how the pixel-colors are globally scattered in the color-spaces. The L2 discrepancy value captures the global degree of discrepancies in color-spaces and enables the formulation of a Deep Discrepancy Learning Process. 
<br>   <br> 
This Deep Discrepancy Learning Process (DDLP) is scalable and makes use of the totality or partially the provided channels in the primary image and is simple to numerically implement without assuming any parametric form in the primary image data contents. The results showed that it captured the reflected pattern in the image with more insights about the colors spatial distribution where the pixel colors are either clumped or scarce, see  <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/IMAGECFLOWCYTOMETRYCONTENTANALYTICS.html"> IFC Using DDLP</a>.
<br>   <br> 

 The DDLP defines image information content as a set of descriptors/covariantes of the primary image color-spaces structures. 
 Many levels of descriptors are provided: 

 <ul>
   <li type="square"> Pixel-level descriptors, the colors spatial distribution where the pixel colors are either clumped or scarce. 
Hence creating one histogram for multi-variable data, i.e. a plot to discover, and show, the underlying frequency distribution of a set of continuous data (RGB colors). We refer to these Pixel-level descriptors as Sensitivity Descriptors.
   </li>
 <li type="square"> New companion Discrepancy Images to the primary image are formed using Pixel-level descriptors. See <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/FLOURESCENCEIMAGECONTENTANALYTICS.html">Fluorescence Imaging Analysis Using Deep Discrepancy Learning Process.</a>
   </li>
     <li type="square"> Global level parameters outlining the entire light scattering proprieties  in the primary image color-spaces structures. 
   </li>
</ul>

These descriptors are used to assess the sensitivity/resolution and image quality and can be used to discern the difference between a number of given primary images.
<!--  augmented  for instance by Kolmogorov-Smirnov test to calculate the pvalues supporting or not the differences statistically. The Kolmogorov-Smirnov test the quality of being the same (similarity) of two independent continuous distributions.  -->
<br>   <br> 

 <h1> Temporal Sensitivity & Resolution </h1> 

 The L2 DDLP provides the Sensitivity Descriptors for the red color and green color in the image content as: 

</li>
<li type="square">  Univariate distribution of H3K4me3 intensity marks, called Rd. </li>
 <li type="square"> Univariate distribution of the H3K27me3 intensity marks, called Gd. </li>
<li type="square">  Bivariate distribution of the intensity representing both the H3K27me3 intensity marks and H3K4me3 intensity  marks, called RGd.</li>
</ul> 
<br> 

 The Discrepancy Image has the color-spaces defined by (Rd,Gd,RGd) where RGd distribution has information about the bi-valency or co-occurrence of H3K4me3 and H3K27me3 marks. The colors and texture in the Discrepancy Image provide insights about the 
 distribution of red and green colors around specific regions of interest (ROI) in the primary image.

<br> <br> 
For an illustrative purpose,  we extracted the images directly from the draft, see Figure 4. The three images named S1,S2,S3,S4,and S5 are used to illustrate our purpose. Both images have H3K4me3 ( as green color) and H3K27me3 ( as red color) and each one has two time points: one at early stage 72 hours ( Time 1) and the second after 2 weeks ( Time 2). 
<br> <br>
We are aware about the fact that the original images are high resolution images. Nevertheless, The extracted images from the publication have the main patterns as in the original images. Our illustration can be conducted on the original images in the same manner.   
<br> <br> 

<h2> Combining the color-space  content at Time 1 with Time 2 as one color space content  </h2>

 One Discrepancy Image is formed by combining Time 1 and 2 to highlight the temporal color changes. 
 The color spaces at Time 1 and 2 are processed as one color space to highlight the discrepancies between Red and Green colors at Time 1 and 2. This process is more efficient to compare the differences in the intensities between Time 1 and 2. The Discrepancy Images are companion to the two combined primary images at Time 1 and 2 and automatically quantify the most informative and relevant features contained in the two combined primary images at Time 1 and 2.
 <br>
 Using L2 DDLP to assess the intensities in  combined images( same sample at two different times) generated by Stimulated emission depletion (STED) microscopy  is our proposed approach to assess the Temporal Sensitivity/Resolution of STED.

<br> 
<br> 
<h4> Combining S1(6.1kpa) at Time 1 and 2 : (Rd,Gd,RGd) </h4>
<div class="image12">
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/STEMCELLRGBMODRGBCOMBINED_rand_000_ALL_s161kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
    <h4> RGd </h4>
       <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_RG_RGBCOMBINED_rand_000_ALL_s161kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
     <h4> Rd </h4>
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_R_RGBCOMBINED_rand_000_ALL_s161kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000"  /></center>
    </div>
     <h4> Gd </h4>
     <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_G_RGBCOMBINED_rand_000_ALL_s161kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
</div>
<h4> Combining S2(10.8kpa) at Time 1 and 2  : (Rd,Gd,RGd) </h4>
 <div class="image12">
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/STEMCELLRGBMODRGBCOMBINED_rand_000_ALL_s2108kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
    <h4> RGd </h4>
       <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_RG_RGBCOMBINED_rand_000_ALL_s2108kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
    <h4> Rd </h4>
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_R_RGBCOMBINED_rand_000_ALL_s2108kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000"  /></center>
    </div>
    <h4> Gd </h4>
     <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_G_RGBCOMBINED_rand_000_ALL_s2108kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
</div>
<h4> Combining S3(15.4kpa) at Time 1 and 2  : (Rd,Gd,RGd) </h4>
 <div class="image12">
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/STEMCELLRGBMODRGBCOMBINED_rand_000_ALL_s3154kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
    <h4> RGd </h4>
       <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_RG_RGBCOMBINED_rand_000_ALL_s3154kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
    <h4> Rd </h4>
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_R_RGBCOMBINED_rand_000_ALL_s3154kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000"  /></center>
    </div>
    <h4> Gd </h4>
     <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_G_RGBCOMBINED_rand_000_ALL_s3154kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
</div>
<h4> Combining S4(20.00kpa) at Time 1 and 2  : (Rd,Gd,RGd) </h4>
 <div class="image12">
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/STEMCELLRGBMODRGBCOMBINED_rand_000_ALL_s4200kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
    <h4> RGd </h4>
       <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_RG_RGBCOMBINED_rand_000_ALL_s4200kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
    <h4> Rd </h4>
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_R_RGBCOMBINED_rand_000_ALL_s4200kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000"  /></center>
    </div>
    <h4> Gd </h4>
     <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_G_RGBCOMBINED_rand_000_ALL_s4200kpa72hr2weeks.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
</div>

<h4> Combining S5(2.47kpa) at Time 1 and 2: (Rd,Gd,RGd) </h4>
 <div class="image12">
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/STEMCELLRGBMODRGBCOMBINED_rand_000_ALL_s5247kpa.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
     <h4> RGd </h4>
       <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_RG_RGBCOMBINED_rand_000_ALL_s5247kpa.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
     <h4> Rd </h4>
    <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_R_RGBCOMBINED_rand_000_ALL_s5247kpa.jpg" alt="Channel" height="1000" width="1000"  /></center>
    </div>
     <h4> Gd </h4>
     <div class="imgContainer">
      <center>  <img src="./STEMCELLS/HISTSTEMCELLRGBMOD_G_RGBCOMBINED_rand_000_ALL_s5247kpa.jpg" alt="Channel" height="1000" width="1000" /></center>
    </div>
</div>
<br>


<h4>  Note  </h4>
The theoretical part of this work was  done when the author was in his PhD thesis (1994-1998), at the University of Savoie, Department of Mathematics, France. The work was shaped toward real applications accordingly to the learned scientific experience. 
<br>   <br> 
Previous Essays:


 <ul>
       <li type="square">  <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/IFCCDTDIDDLP.html"> 
Imaging Flow Cytometry (IFC), Sensitivity Resolution  Image Quality, CCD Camera in Time-Delay Integration Using Deep Discrepancy Learning Process (DDLP) </a>
   </li>  
    <li type="square">  <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/IMAGECFLOWCYTOMETRYCONTENTANALYTICS.html"> Imaging Flow Cytometry Using Deep Discrepancy Learning Process.</a>
   </li>
   <li type="square"> <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/FLOURESCENCEIMAGECONTENTANALYTICS.html">Fluorescence Imaging Analysis Using Deep Discrepancy Learning Process </a>
   </li>
  <li  <li type="square"> <a target="alone"  href="http://efaysal.github.io/SocioEconomicEcosystem/IMAGECONTENTANALYTICS.html"> Image Analytics Using Deep Discrepancy Learning Process. </a>
   </li>
</ul>


 <br>   <br> 
<h4>   Author scientific profile:  </h4>
Statistics and Applied Mathematics for Data Analytics, Identify opportunities to apply Mathematical Statistics, Numerical Methods, Machine Learning and Pattern Recognition to investigate and implement solutions to the field of Data Content Analytics. Data prediction via computational methods to predict from massive amounts of data (Big Data Content). These methods included clustering, regression, survival analysis, neural network, classification , ranking, deep discrepancy learning .
 <br>   <br> 


    <div>
    <a target="alone"  href="https://github.com/efaysal" style="color:black"> Author: Faysal.El.Khettabi@gmail.com , Living in Vancouver, BC, Canada.</a>
    <br> 
   The MIT License (MIT) Copyright 1994-2017, Faysal El Khettabi, Numerics&Analytics, All Rights Reserved.
     </div> 
   
</section>
</div>
 
</body>
</html>
